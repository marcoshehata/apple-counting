{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fcc052",
   "metadata": {},
   "source": [
    "# DEMO: applicazione YOLO-World + IoU sul conteggio delle mele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507419f",
   "metadata": {},
   "source": [
    "Codice di dimostrazione del funzionamento algoritmico (logica in batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c5c47",
   "metadata": {},
   "source": [
    "Il progetto permette invece di caricare un video e di vedere il processing real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ee0392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# LIBRERIE\n",
    "# -----------------------\n",
    "import cv2\n",
    "import supervision as sv\n",
    "from inference.models.yolo_world.yolo_world import YOLOWorld\n",
    "import numpy as np\n",
    "from utils.SimpleIoUTracker import SimpleIoUTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db515e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# PARAMETRI\n",
    "# -----------------------\n",
    "\n",
    "INPUT_VIDEO = \"apple_tree_video.mp4\"\n",
    "OUTPUT_VIDEO_obj_only = \"output_annotated_obj_only.mp4\"\n",
    "OUTPUT_VIDEO_obj_and_track = \"output_annotated_obj_and_track.mp4\"\n",
    "\n",
    "CONFIDENCE = 0.05\n",
    "TRAIL_LENGTH = 30  # lunghezza scia --> solo per tracking\n",
    "\n",
    "classes = [\"apple\", \"red apple\", \"ripe apple\", \"fruit\"]  # prompt testuale YOLO-World, si puÃ² aggiungere anche Yellow Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2d21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating inference sessions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded in 1.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2026-02-01 12:34:08.413268 [W:onnxruntime:, coreml_execution_provider.cc:112 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 17 number of nodes in the graph: 985 number of nodes supported by CoreML: 43\u001b[m\n",
      "\u001b[0;93m2026-02-01 12:34:09.620445 [W:onnxruntime:, helper.cc:83 IsInputSupported] CoreML does not support input dim > 16384. Input:token_embedding.weight, shape: {49408,512}\u001b[m\n",
      "\u001b[0;93m2026-02-01 12:34:09.620659 [W:onnxruntime:, coreml_execution_provider.cc:112 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 15 number of nodes in the graph: 1003 number of nodes supported by CoreML: 32\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Selected Model\n",
    "# -----------------------\n",
    "\n",
    "model = YOLOWorld(model_id=\"yolo_world/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943b036",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1408c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¹ Video: 360x640 @ 24.0fps, 192 frames\n",
      "Frame 1: 19 det, IDs=[1 2 3 4 5]...\n",
      "Frame 2: 18 det, IDs=[1 3 5 4 2]...\n",
      "Frame 3: 16 det, IDs=[1 3 2 5 6]...\n",
      "Frame 4: 16 det, IDs=[ 1  3  7 11 12]...\n",
      "Frame 5: 18 det, IDs=[ 1  7  3 12  4]...\n",
      "Frame 6: 19 det, IDs=[1 7 3 4 8]...\n",
      "Frame 7: 16 det, IDs=[ 7  3  4  1 10]...\n",
      "Frame 8: 18 det, IDs=[ 7  3  4  1 10]...\n",
      "Frame 9: 17 det, IDs=[ 7  3  4 10  8]...\n",
      "Frame 10: 17 det, IDs=[ 3 10  7  1  8]...\n",
      "ðŸ“¹ Frame 30: 16 tracked, 22 ID univoci totali\n",
      "ðŸ“¹ Frame 60: 12 tracked, 26 ID univoci totali\n",
      "ðŸ“¹ Frame 90: 13 tracked, 33 ID univoci totali\n",
      "ðŸ“¹ Frame 120: 20 tracked, 42 ID univoci totali\n",
      "ðŸ“¹ Frame 150: 14 tracked, 46 ID univoci totali\n",
      "ðŸ“¹ Frame 180: 15 tracked, 52 ID univoci totali\n",
      "\n",
      "âœ… Video salvato: output_annotated_obj_and_track.mp4\n",
      "ðŸ“Š Frame totali: 192\n",
      "ðŸ“Š Oggetti tracciati totali: 2767\n",
      "ðŸ“Š ID univoci assegnati: 56\n",
      "ðŸ“Š Media detection/frame: 14.4\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# VIDEO INPUT\n",
    "# -----------------------\n",
    "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Errore nell'apertura del video\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"ðŸ“¹ Video: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
    "\n",
    "# -----------------------\n",
    "# VIDEO OUTPUT\n",
    "# -----------------------\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\n",
    "    OUTPUT_VIDEO_obj_and_track,\n",
    "    fourcc,\n",
    "    fps,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# TRACKER\n",
    "# -----------------------\n",
    "tracker = SimpleIoUTracker(iou_threshold=0.3, max_age=60)\n",
    "\n",
    "# -----------------------\n",
    "# ANNOTATORI\n",
    "# -----------------------\n",
    "box_annotator = sv.BoxAnnotator(color=sv.Color.RED, thickness=2)\n",
    "\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    text_thickness=1,\n",
    "    text_scale=0.3,\n",
    "    text_color=sv.Color.WHITE,\n",
    "    color=sv.Color.RED\n",
    ")\n",
    "\n",
    "trace_annotator = sv.TraceAnnotator(\n",
    "    color=sv.Color.RED,\n",
    "    position=sv.Position.CENTER,\n",
    "    trace_length=TRAIL_LENGTH,\n",
    "    thickness=2\n",
    ")\n",
    "\n",
    "FILL_COLOR = (0, 0, 255)\n",
    "FILL_ALPHA = 0.5\n",
    "\n",
    "# -----------------------\n",
    "# LOOP FRAME\n",
    "# -----------------------\n",
    "frame_count = 0\n",
    "total_tracked = 0\n",
    "unique_ids = set()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "    results = model.infer(\n",
    "        frame,\n",
    "        text=classes,\n",
    "        confidence=CONFIDENCE\n",
    "    )\n",
    "    detections = sv.Detections.from_inference(results)\n",
    "    detections = tracker.update(detections)\n",
    "\n",
    "    # Debug primi 10 frame\n",
    "    if frame_count <= 10:\n",
    "        has_ids = len(detections.tracker_id) > 0\n",
    "        ids_str = str(detections.tracker_id[:5]) if has_ids else \"[]\"\n",
    "        print(f\"Frame {frame_count}: {len(detections)} det, IDs={ids_str}...\")\n",
    "\n",
    "    if len(detections) == 0 or len(detections.tracker_id) == 0:\n",
    "        out.write(frame)\n",
    "        continue\n",
    "\n",
    "    total_tracked += len(detections.tracker_id)\n",
    "    unique_ids.update(detections.tracker_id)\n",
    "\n",
    "    labels = [str(int(tid)) for tid in detections.tracker_id]\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    # TRACE PRIMA\n",
    "    annotated_frame = trace_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections\n",
    "    )\n",
    "\n",
    "    # FILL ROSSO TRASPARENTE\n",
    "    overlay = annotated_frame.copy()\n",
    "    for box in detections.xyxy.astype(int):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(overlay, (x1, y1), (x2, y2), FILL_COLOR, -1)\n",
    "\n",
    "    annotated_frame = cv2.addWeighted(\n",
    "        overlay,\n",
    "        FILL_ALPHA,\n",
    "        annotated_frame,\n",
    "        1 - FILL_ALPHA,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # BOX + LABEL SOPRA\n",
    "    annotated_frame = box_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections\n",
    "    )\n",
    "\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections,\n",
    "        labels=labels\n",
    "    )\n",
    "\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    if frame_count % 30 == 0:\n",
    "        print(\n",
    "            f\"ðŸ“¹ Frame {frame_count}: \"\n",
    "            f\"{len(detections.tracker_id)} tracked, \"\n",
    "            f\"{len(unique_ids)} ID univoci totali\"\n",
    "        )\n",
    "\n",
    "# -----------------------\n",
    "# CLEANUP\n",
    "# -----------------------\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"\\nâœ… Video salvato: {OUTPUT_VIDEO_obj_and_track}\")\n",
    "print(f\"ðŸ“Š Frame totali: {frame_count}\")\n",
    "print(f\"ðŸ“Š Oggetti tracciati totali: {total_tracked}\")\n",
    "print(f\"ðŸ“Š ID univoci assegnati: {len(unique_ids)}\")\n",
    "print(f\"ðŸ“Š Media detection/frame: {total_tracked / frame_count:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929efd48",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
